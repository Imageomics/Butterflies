{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd37fb53-f616-47d3-b22a-dfd4cca1ebd8",
   "metadata": {},
   "source": [
    "### GradCam Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9cc26",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e0240758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c8a7557d-eff3-48a2-8e48-2ccbb54fb0db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.models import resnet\n",
    "from tqdm import tqdm \n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import catalyst.dl as dl\n",
    "from catalyst.contrib.nn import (\n",
    "    ArcFace,\n",
    "    CosFace,\n",
    "    AdaCos,\n",
    "    SubCenterArcFace,\n",
    "    CurricularFace,\n",
    "    ArcMarginProduct,\n",
    ")\n",
    "\n",
    "# gradcam: https://github.com/jacobgil/pytorch-grad-cam\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# # all model labels per input\n",
    "from src.dir_paths.figures_paths import get_figures_path\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \",device)\n",
    "\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773b31e-d88a-4c8d-94d9-a430a47887fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define species label dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5b49a0e1-0533-43f8-b9ec-b3d18afb8b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## EratoNet\n",
    "index2species_erato = {\n",
    "0: 'Heliconius erato ssp. phyllis',\n",
    "1: 'Heliconius erato ssp. dignus',\n",
    "2: 'Heliconius erato ssp. lativitta',\n",
    "3: 'Heliconius erato ssp. etylus',\n",
    "4: 'Heliconius erato ssp. cyrbia',\n",
    "5: 'Heliconius erato ssp. amalfreda', #meriana is the melpomene mimic\n",
    "6: 'Heliconius erato ssp. venus',\n",
    "7: 'Heliconius erato ssp. hydara',\n",
    "8: 'Heliconius erato ssp. petiverana',\n",
    "9: 'Heliconius erato ssp. notabilis'}\n",
    "\n",
    "index2species_melpomene = {\n",
    "0: 'Heliconius melpomene ssp. nanna',\n",
    "1: 'Heliconius melpomene ssp. bellula',\n",
    "2: 'Heliconius melpomene ssp. malleti',\n",
    "3: 'Heliconius melpomene ssp. ecuadorensis',\n",
    "4: 'Heliconius melpomene ssp. cythera',\n",
    "5: 'Heliconius melpomene ssp. meriana', #Missing from index2species in dorsal images\n",
    "6: 'Heliconius melpomene ssp. vulcanus',\n",
    "7: 'Heliconius melpomene ssp. melpomene',\n",
    "8: 'Heliconius melpomene ssp. rosina',\n",
    "9: 'Heliconius melpomene ssp. plesseni',\n",
    "}\n",
    "\n",
    "index2species = {0: 'Heliconius melpomene ssp. ecuadorensis',\n",
    " 1: 'Heliconius melpomene ssp. nanna',\n",
    " 2: 'Heliconius melpomene ssp. rosina',\n",
    " 3: 'Heliconius erato ssp. phyllis',\n",
    " 4: 'Heliconius erato ssp. dignus',\n",
    " 5: 'Heliconius melpomene ssp. bellula',\n",
    " 6: 'Heliconius erato ssp. lativitta',\n",
    " 7: 'Heliconius melpomene ssp. vulcanus',\n",
    " 8: 'Heliconius erato ssp. etylus',\n",
    " 9: 'Heliconius melpomene ssp. plesseni',\n",
    " 10: 'Heliconius melpomene ssp. malleti',\n",
    " 11: 'Heliconius erato ssp. cyrbia',\n",
    " 12: 'Heliconius erato ssp. amalfreda',\n",
    " 13: 'Heliconius erato ssp. venus',\n",
    " 14: 'Heliconius erato ssp. hydara',\n",
    " 15: 'Heliconius melpomene ssp. meriana', \n",
    " 16: 'Heliconius erato ssp. petiverana',\n",
    " 17: 'Heliconius melpomene ssp. cythera',\n",
    " 18: 'Heliconius erato ssp. notabilis',\n",
    " 19: 'Heliconius melpomene ssp. melpomene'}\n",
    "\n",
    "#indices in the dictionaries above are assigned such that the mimic pair will share the same numerical label\n",
    "species2index_erato = {v:k for k,v in index2species_erato.items()}\n",
    "species2index_melpomene = {v:k for k,v in index2species_melpomene.items()}\n",
    "species2index = {v:k for k,v in index2species.items()}\n",
    "\n",
    "n_classes = len(index2species_erato)\n",
    "num_classes = n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f1b5d-5d78-41d5-914f-9c04a152f898",
   "metadata": {},
   "source": [
    "## Select Acuity and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "14f45947-fd2e-4c40-a05d-8f385d2322f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuity:  kingfisher_acuity\n",
      "Model:  MelpomeneNet\n",
      "False True\n"
     ]
    }
   ],
   "source": [
    "## ----- uncomment the name of the dataset you want to work with ------\n",
    "# acuity = 'no_acuity_white_background'\n",
    "# acuity = 'no_acuity' #Done, Done, done\n",
    "# acuity = 'heliconius_male_behavioral_acuity' #Done, done, done\n",
    "# acuity = 'heliconius_female_behavioral_acuity' #Done, done, done\n",
    "# acuity = 'heliconius_male_morphological_acuity' #Done, done, done\n",
    "# acuity = 'heliconius_female_morphological_acuity' #Done, done, done\n",
    "acuity = 'kingfisher_acuity' #Done, done\n",
    "\n",
    "## ----- uncomment model name ------\n",
    "# model_name = 'RegularSpeciesClassification'\n",
    "# model_name = 'EratoNet'\n",
    "model_name = 'MelpomeneNet'\n",
    "\n",
    "print('Acuity: ', acuity)\n",
    "print('Model: ', model_name)\n",
    "\n",
    "erato_net = True if model_name == 'EratoNet' else False\n",
    "melpomene_net = True if model_name == 'MelpomeneNet' else False\n",
    "\n",
    "print(erato_net, melpomene_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c17b4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "088b2be9-fd91-4586-a211-4e169d2e2fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 2)\n",
      "(142, 2)\n",
      "(2396, 2)\n",
      "(256, 2)\n",
      "Image Dataset: /fs/ess/PAS2136/Butterfly/Model_Mimic/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/\n",
      "Data Split:  /fs/ess/PAS2136/Butterfly/Model_Mimic/Data_Splits/MelpomeneNet/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/\n"
     ]
    }
   ],
   "source": [
    "#read in datasets\n",
    "from src.dir_paths.dataset_paths import get_image_dataset_path\n",
    "from src.dir_paths.train_val_test_paths import get_split_csvs\n",
    "\n",
    "#path to images with the applied selected acuity\n",
    "dataset_path = get_image_dataset_path(acuity)\n",
    "\n",
    "#path to train/val/test split csvs \n",
    "main = get_split_csvs(acuity, model_name)\n",
    "\n",
    "if model_name == 'RegularSpeciesClassification':\n",
    "    train_df = pd.read_csv(main + 'train.csv')\n",
    "    val_df = pd.read_csv(main + 'val.csv')\n",
    "    test_df = pd.read_csv(main + 'test.csv')\n",
    "\n",
    "    print(train_df.shape) ##5512, 2\n",
    "    print(val_df.shape) #613, 2\n",
    "    print(test_df.shape) #1532, 2\n",
    "\n",
    "elif erato_net or melpomene_net:\n",
    "    train_df = pd.read_csv(main + 'train.csv')\n",
    "    val_df = pd.read_csv(main + 'val.csv')\n",
    "    test_df_erato = pd.read_csv(main + 'test_erato.csv')\n",
    "    test_df_melpomene = pd.read_csv(main + 'test_melpomene.csv')\n",
    "\n",
    "    print(train_df.shape)\n",
    "    print(val_df.shape) \n",
    "    print(test_df_erato.shape)\n",
    "    print(test_df_melpomene.shape) \n",
    "\n",
    "#EratoNet (no acuity)\n",
    "# (1728, 2)\n",
    "# (241, 2)\n",
    "# (433, 2)\n",
    "# (1420, 2)\n",
    "\n",
    "print('Image Dataset:', dataset_path)\n",
    "print('Data Split: ', main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "03b2578a-6ec2-4f9f-81f2-4b22fee06fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MelpomeneNet\n",
      "Number of train samples - 1020\n",
      "Number of valid samples - 142\n",
      "Number of test melpomene samples -  256\n",
      "Number of test erato samples -  2396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x2b49975eaa90>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x2b48575e2cd0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x2b4833eaa400>}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataloader import read_image, read_sized_image, get_transforms, get_loader\n",
    "\n",
    "if main.split('/')[7] == \"MimicsNet\":\n",
    "    #create lists of image filepaths and their labels for each split\n",
    "    train_images = list(train_df['path'])\n",
    "    valid_images = list(val_df['path'])\n",
    "    test_images = list(test_df['path'])\n",
    "\n",
    "    #labels were encoded so that mimics share the same label\n",
    "    print('Using MimicsNet Labels')\n",
    "    train_targets = list(train_df['label'])\n",
    "    valid_targets = list(val_df['label'])\n",
    "    test_targets = list(test_df['label'])\n",
    "    \n",
    "elif main.split('/')[7] == \"EratoNet\":\n",
    "    print('EratoNet')\n",
    "    train_images = list(train_df['path'])\n",
    "    valid_images = list(val_df['path'])\n",
    "    test_images_erato = list(test_df_erato['path'])\n",
    "    test_images_melpomene = list(test_df_melpomene['path'])\n",
    "\n",
    "    train_targets = [species2index_erato[str(elem).split(\"/\")[7]] for elem in train_images]\n",
    "    valid_targets = [species2index_erato[str(elem).split(\"/\")[7]] for elem in valid_images]\n",
    "    test_targets_erato = [species2index_erato[str(elem).split(\"/\")[7]] for elem in test_images_erato]\n",
    "    test_targets_melpomene = [species2index_melpomene[str(elem).split(\"/\")[7]] for elem in test_images_melpomene]\n",
    "    test_targets_melpomene_actual = [str(elem).split(\"/\")[7] for elem in test_images_melpomene] #so that we have the true melpomene label encodings for each image\n",
    "\n",
    "    print(\"Number of train samples -\", len(train_images))\n",
    "    print(\"Number of valid samples -\", len(valid_images))\n",
    "    print(\"Number of test erato samples - \",len(test_images_erato))\n",
    "    print(\"Number of test melpomene samples - \",len(test_images_melpomene))\n",
    "\n",
    "elif main.split('/')[7] == \"MelpomeneNet\":\n",
    "    print('MelpomeneNet')\n",
    "    train_images = list(train_df['path'])\n",
    "    valid_images = list(val_df['path'])\n",
    "    test_images_erato = list(test_df_erato['path'])\n",
    "    test_images_melpomene = list(test_df_melpomene['path'])\n",
    "\n",
    "    train_targets = [species2index_melpomene[str(elem).split(\"/\")[7]] for elem in train_images]\n",
    "    valid_targets = [species2index_melpomene[str(elem).split(\"/\")[7]] for elem in valid_images]\n",
    "    test_targets_melpomene = [species2index_melpomene[str(elem).split(\"/\")[7]] for elem in test_images_melpomene]\n",
    "    test_targets_erato = [species2index_erato[str(elem).split(\"/\")[7]] for elem in test_images_erato]\n",
    "    test_targets_erato_actual = [str(elem).split(\"/\")[7] for elem in test_images_erato] #so that we have the true melpomene label encodings for each image\n",
    "\n",
    "    print(\"Number of train samples -\", len(train_images))\n",
    "    print(\"Number of valid samples -\", len(valid_images))\n",
    "    print(\"Number of test melpomene samples - \",len(test_images_melpomene))\n",
    "    print(\"Number of test erato samples - \",len(test_images_erato))\n",
    "\n",
    "else:\n",
    "    #regular species classification\n",
    "    train_images = list(train_df['path'])\n",
    "    valid_images = list(val_df['path'])\n",
    "    test_images = list(test_df['path'])\n",
    "\n",
    "    train_targets = [species2index[str(elem).split(\"/\")[7]] for elem in train_images]\n",
    "    valid_targets = [species2index[str(elem).split(\"/\")[7]] for elem in valid_images]\n",
    "    test_targets = [species2index[str(elem).split(\"/\")[7]] for elem in test_images]\n",
    "\n",
    "    print(\"Number of train samples -\", len(train_images))\n",
    "    print(\"Number of valid samples -\", len(valid_images))\n",
    "    print(\"Number of test samples - \",len(test_images))\n",
    "\n",
    "#create dataloaders for each split of data\n",
    "batch = 32\n",
    "train_dataset, train_loader = get_loader(\"train\", train_images, train_targets, batch_size=batch, num_workers=1)\n",
    "valid_dataset, valid_loader = get_loader(\"valid\", valid_images, valid_targets, batch_size=batch, num_workers=1)\n",
    "\n",
    "if erato_net or melpomene_net:\n",
    "    test_dataset_erato, test_loader_erato, = get_loader(\"test\", test_images_erato, test_targets_erato, batch_size=batch, num_workers=1)\n",
    "    test_dataset_melpomene, test_loader_melpomene, = get_loader(\"test\", test_images_melpomene, test_targets_melpomene, batch_size=batch, num_workers=1)\n",
    "    \n",
    "    #create dictionary with each of our dataloaders\n",
    "    #only include the ID loader --> leave out the mimic loader for now. We'll work with that one independently\n",
    "    loaders = { \"train\": train_loader,\n",
    "            \"valid\": valid_loader,\n",
    "            \"test\": test_loader_erato if erato_net else test_loader_melpomene\n",
    "            }\n",
    "\n",
    "else:\n",
    "    test_dataset, test_loader, = get_loader(\"test\", test_images, test_targets, batch_size=batch, num_workers=1)\n",
    "    #create dictionary with each of our dataloaders\n",
    "    loaders = { \"train\": train_loader,\n",
    "            \"valid\": valid_loader,\n",
    "            \"test\": test_loader\n",
    "            }\n",
    "\n",
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df65f7-8a75-48e9-9cf4-079c766cd64e",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "01840264-427e-403e-9b82-5a6513b37541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ckpt: /fs/ess/PAS2136/Butterfly/Model_Mimic/resnet_arcface_logs/MelpomeneNet/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/checkpoints/classification_ckpt.pth\n",
      "Num Classes:  10\n"
     ]
    }
   ],
   "source": [
    "#read in the model\n",
    "from src.utils import load_model\n",
    "from src.dir_paths.model_log_paths import get_logdir\n",
    "from src.model import ResNetEncoder, EncoderWithHead\n",
    "\n",
    "model_path = get_logdir(acuity, model_name) + '/checkpoints/classification_ckpt.pth'\n",
    "\n",
    "#load in model with weights\n",
    "num_classes = 20 if model_name == 'RegularSpeciesClassification' else 10 #20 (0r 10 if mimicsnet, eratonet, melpomene net)\n",
    "\n",
    "encoder = ResNetEncoder(\"resnet50\", 128)\n",
    "model   = EncoderWithHead(encoder,\n",
    "                          ArcFace(128, num_classes, s=2**0.5*np.log(num_classes - 1), m=0.25))\n",
    "\n",
    "model = load_model(model, model_path, device)\n",
    "encoder = model.encoder\n",
    "device = 'cpu'\n",
    "\n",
    "print('Model Ckpt:', model_path)\n",
    "print('Num Classes: ', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570124f",
   "metadata": {},
   "source": [
    "## GradCam - One label (target label=ground truth) per image (Butterflies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fbb98848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "# for name, layer in model.named_modules():\n",
    "#     print(name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "53a6df96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs/ess/PAS2136/Butterfly/Model_Mimic/Figures/MelpomeneNet/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/gradcam/\n"
     ]
    }
   ],
   "source": [
    "save_folder = get_figures_path(acuity, model_name)\n",
    "plot_path = save_folder + '/gradcam/'\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "print(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e7a8cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Heliconius melpomene ssp. ecuadorensis',\n",
       " 1: 'Heliconius melpomene ssp. nanna',\n",
       " 2: 'Heliconius melpomene ssp. rosina',\n",
       " 3: 'Heliconius erato ssp. phyllis',\n",
       " 4: 'Heliconius erato ssp. dignus',\n",
       " 5: 'Heliconius melpomene ssp. bellula',\n",
       " 6: 'Heliconius erato ssp. lativitta',\n",
       " 7: 'Heliconius melpomene ssp. vulcanus',\n",
       " 8: 'Heliconius erato ssp. etylus',\n",
       " 9: 'Heliconius melpomene ssp. plesseni',\n",
       " 10: 'Heliconius melpomene ssp. malleti',\n",
       " 11: 'Heliconius erato ssp. cyrbia',\n",
       " 12: 'Heliconius erato ssp. amalfreda',\n",
       " 13: 'Heliconius erato ssp. venus',\n",
       " 14: 'Heliconius erato ssp. hydara',\n",
       " 15: 'Heliconius melpomene ssp. meriana',\n",
       " 16: 'Heliconius erato ssp. petiverana',\n",
       " 17: 'Heliconius melpomene ssp. cythera',\n",
       " 18: 'Heliconius erato ssp. notabilis',\n",
       " 19: 'Heliconius melpomene ssp. melpomene'}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "58b228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meriana is 15\n",
    "\n",
    "# AllNet - getting Meriana samples\n",
    "meriana_images = [n for n in train_images if n.split('/')[-2] == 'Heliconius melpomene ssp. meriana']\n",
    "meriana_targets = [t for t in train_targets if t == 15]\n",
    "\n",
    "test_images = meriana_images\n",
    "test_targets = meriana_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bc20197d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "/fs/ess/PAS2136/Butterfly/Model_Mimic/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/Heliconius melpomene ssp. meriana/13819_H_m_meriana_D.JPG.png\n",
      "torch.Size([1, 10])\n",
      "Prediction: 5 | Heliconius melpomene ssp. meriana\n",
      "Actual label: 5 | Heliconius melpomene ssp. meriana\n",
      "/fs/ess/PAS2136/Butterfly/Model_Mimic/Figures/MelpomeneNet/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/gradcam/Heliconius melpomene ssp. meriana/13819_H_m_meriana_D.JPG.png\n",
      "/fs/ess/PAS2136/Butterfly/Model_Mimic/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/Heliconius melpomene ssp. meriana/13715_H_m_meriana_D.JPG.png\n",
      "torch.Size([1, 10])\n",
      "Prediction: 5 | Heliconius melpomene ssp. meriana\n",
      "Actual label: 5 | Heliconius melpomene ssp. meriana\n",
      "/fs/ess/PAS2136/Butterfly/Model_Mimic/Figures/MelpomeneNet/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/gradcam/Heliconius melpomene ssp. meriana/13715_H_m_meriana_D.JPG.png\n"
     ]
    }
   ],
   "source": [
    "# single image example - trying out different methods besides just GradCam\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget, ClassifierOutputSoftmaxTarget\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad, LayerCAM, GradCAMElementWise, EigenGradCAM\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "test_transforms = albu.Compose([\n",
    "            albu.Resize(224, 224),\n",
    "            albu.Normalize(),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "resize_transform = albu.Compose([\n",
    "            albu.Resize(224, 224),\n",
    "        ])\n",
    "\n",
    "# create a wrapper for our model\n",
    "class WrapperModel(torch.nn.Module):\n",
    "        def __init__(self, model, target):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.target = target\n",
    "        def forward(self, x):\n",
    "            self.model.eval()\n",
    "            return self.model(x, targets=self.target)\n",
    "        \n",
    "# define the layer for whom we want to visualize output\n",
    "encoder.eval()\n",
    "# target_layers = [encoder.base.layer4]\n",
    "target_layers = [layer for name, layer in model.named_modules()]\n",
    "\n",
    "#set of labels\n",
    "if erato_net:\n",
    "    labels = list(index2species_erato.keys())\n",
    "    label_map = index2species_erato\n",
    "    test_images = test_images_erato + test_images_melpomene\n",
    "    test_targets = test_targets_erato + test_targets_melpomene\n",
    "elif melpomene_net:\n",
    "    labels = list(index2species_melpomene.keys())\n",
    "    label_map = index2species_melpomene\n",
    "    test_images = test_images_erato + test_images_melpomene\n",
    "    test_targets = test_targets_erato + test_targets_melpomene\n",
    "\n",
    "    # getting Meriana samples (TEMPORARY - REMOVE ONCE DONE)\n",
    "    meriana_images = [n for n in train_images if n.split('/')[-2] == 'Heliconius melpomene ssp. meriana']\n",
    "    meriana_targets = [t for t in train_targets if t == 5]\n",
    "\n",
    "    test_images = meriana_images\n",
    "    test_targets = meriana_targets\n",
    "\n",
    "else:\n",
    "    labels = list(index2species.keys())\n",
    "    label_map = index2species\n",
    "\n",
    "\n",
    "# idx = 70\n",
    "# for img_path, target in zip(train_images[idx:idx+1], train_targets[idx:idx+1]):\n",
    "print(len(test_images))\n",
    "for img_path, target in zip(test_images, test_targets):\n",
    "    print(img_path)\n",
    "    results = []\n",
    "    result_labels = []\n",
    "\n",
    "    #format our image as a tensor for gradcam\n",
    "    orig_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB) #(256,256,3)\n",
    "    orig_img = resize_transform(image=orig_img)[\"image\"] #(224,224,3)\n",
    "\n",
    "    input_tensor = test_transforms(image=orig_img)[\"image\"] #(3, 224, 224)apply transforms and convert to tensor    \n",
    "    repeated_tensor = input_tensor[None, :] #(1,3,224,224) - add batch dim\n",
    "    \n",
    "    targets_for_gradcam = [ClassifierOutputTarget(target)] #get CAM for ground truth label\n",
    "    result_labels.append(target)\n",
    "\n",
    "    #get the predicted label our model would assign to the current image\n",
    "    with torch.no_grad():\n",
    "        out = model(input_tensor[None, :], targets=torch.tensor(target, device=device))\n",
    "        print(out.shape)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        print(f\"Prediction: {pred.item()} | {label_map[pred.item()]}\")\n",
    "        print(f\"Actual label: {target} | {label_map[target]}\")\n",
    "\n",
    "    #instantiate wrapper model for current target\n",
    "    wrapped_model = WrapperModel(model, torch.tensor(target, device=device))\n",
    "\n",
    "    #build the CAM object once and re-use it on many images\n",
    "    cam = GradCAM(model=wrapped_model, target_layers=target_layers, use_cuda=False)\n",
    "\n",
    "    # get CAM of ground truth label\n",
    "    batch_results = cam(input_tensor=repeated_tensor, \n",
    "                        targets=targets_for_gradcam,\n",
    "                        aug_smooth=False,\n",
    "                        eigen_smooth=False) \n",
    "    \n",
    "    for grayscale_cam in batch_results:\n",
    "        visualization = show_cam_on_image(np.float32(orig_img)/255,\n",
    "                                        grayscale_cam,\n",
    "                                        use_rgb=True)\n",
    "        # visualization = cv2.resize(visualization,(visualization.shape[1]//2, visualization.shape[0]//2))\n",
    "        # plt.imshow(visualization)\n",
    "    \n",
    "    # save the visualization\n",
    "    img_folder = f\"{plot_path}{img_path.split('/')[-2]}/\"\n",
    "    img_name = img_path.split('/')[-2] + \"/\" + img_path.split('/')[-1] \n",
    "    \n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "    print(f\"{plot_path}{img_name}\")\n",
    "    cv2.imwrite(f\"{plot_path}{img_name}\", cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d16ac5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "/fs/ess/PAS2136/Butterfly/Model_Mimic/Figures/MelpomeneNet/model_mimic_images_256_256_removed_background_kingfisher_acuity_dorsal/gradcam/\n",
      "MelpomeneNet kingfisher_acuity\n"
     ]
    }
   ],
   "source": [
    "print('Done.')\n",
    "print(plot_path)\n",
    "print(model_name, acuity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420d831",
   "metadata": {},
   "source": [
    "`To do: `\n",
    "\n",
    "`Get maps for all images and save each horizontal stack under the image name and the true label associated with it`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
